from mpmath import mp
import numpy as np
import torch
from typing import List

mp.dps = 500
def gen_data(mu: float, delta: List[int], n: int, d: int):
    mu = np.full((n, d), mu, dtype=np.float64)
    noise = np.random.normal(loc = 0, scale = 1, size=(n, d))
    X = mu + noise
    labels = np.zeros(n)
    if len(delta) == 1:
        n_anomalies = int(n * 0.05)
        idx = np.random.choice(n, n_anomalies, replace=False)
        X[idx] = X[idx] + delta[0]
        if delta[0] != 0:
            labels[idx] = np.ones(n_anomalies)
    else:
        # In this case, we generate data for source domain.
        # 5% of the data is abnormal.
        # Anomalies are generated by randomly adding deltas to the data.
        n_anomalies = int(n * 0.05)
        idx = np.random.choice(n, n_anomalies, replace=False)
        if 0 in delta: 
            delta.pop(delta.index(0))
        if len(delta) != 0:
            split_points = sorted(np.random.choice(range(1, len(idx)), len(delta) - 1, replace=False))
            segments = np.split(idx, split_points)
            for i, segment in enumerate(segments):
                X[segment] = X[segment] + delta[i]
            labels[idx] = 1
    return X, labels

def intersect(itv1, itv2):
    # print(itv1, itv2)
    itv = [max(itv1[0], itv2[0]), min(itv1[1], itv2[1])]
    if itv[0] > itv[1]:
        return None    
    return itv

def solve_linear_inequality(u, v): #u + vz < 0
    u = float(u)
    v = float(v)
    if (v > -1e-16 and v < 1e-16):
        if (u < 0):
            return [-np.Inf, np.Inf]
        else:
            print('error')
            return None
    if (v < 0):
        return [-u/v, np.Inf]
    return [np.NINF, -u/v]

def get_dnn_interval(Xtj, a, b, model):
    layers = []

    for name, param in model.generator.named_children():
        temp = dict(param._modules)
        
        for layer_name in temp.values():
            if ('Linear' in str(layer_name)):
                layers.append('Linear')
            elif ('ReLU' in str(layer_name)):
                layers.append('ReLU')

    ptr = 0
    itv = [np.NINF, np.Inf]
    u = a
    v = b
    temp = Xtj
    weight = None
    bias = None
    for name, param in model.generator.named_parameters():
        if (layers[ptr] == 'Linear'):
            if ('weight' in name):
                weight = param.data.cpu().detach().numpy()
            elif ('bias' in name):
                bias = param.data.cpu().detach().numpy().reshape(-1, 1)
                ptr += 1
                temp = weight.dot(temp) + bias
                u = weight.dot(u) + bias
                v = weight.dot(v)

        if (ptr < len(layers) and layers[ptr] == 'ReLU'):
            ptr += 1
            Relu_matrix = np.zeros((temp.shape[0], temp.shape[0]))
            sub_itv = [np.NINF, np.inf]
            for i in range(temp.shape[0]):
                if temp[i] > 0:
                    sub_itv = intersect(sub_itv, solve_linear_inequality(-u[i], -v[i]))
                else:
                    sub_itv = intersect(sub_itv, solve_linear_inequality(u[i], v[i]))
                    temp[i] = 0
                    u[i] = 0
                    v[i] = 0
            itv = intersect(itv, sub_itv)
            temp = Relu_matrix.dot(temp)
            u = Relu_matrix.dot(u)
            v = Relu_matrix.dot(v)

    return itv, u, v

def get_ad_interval(X, X_hat, O, a, b, model):
    itv = [np.NINF, np.Inf]
    for i in range(X.shape[0]):
        itv = intersect(itv, get_dnn_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1), model)[0])
    _, uo, vo = get_dnn_interval(X[O].reshape(-1, 1), a[O].reshape(-1, 1), b[O].reshape(-1, 1), model)
    I = np.ones((X_hat.shape[1],1))
    sub_itv = [np.NINF, np.inf]
    for i in range(X.shape[0]):
        if (i != O):
            _, ui, vi = get_dnn_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1), model)
            u = uo - ui
            v = vo - vi 
            u = I.T.dot(u)[0][0]
            v = I.T.dot(v)[0][0]
            sub_itv = intersect(sub_itv, solve_linear_inequality(-u, -v))
    itv = intersect(itv, sub_itv)
    return itv

def compute_yz(X, etaj, zk, n):
    sq_norm = (np.linalg.norm(etaj))**2

    e1 = np.identity(n) - (np.dot(etaj, etaj.T))/sq_norm
    a = np.dot(e1, X)

    b = etaj/sq_norm

    Xz = a + b*zk

    return Xz, a, b

def parametric_wdgrl(Xz, a, b, n, zk, model):
    Xz = torch.FloatTensor(Xz)
    Xz_hat = model.extract_feature(Xz.cuda())
    Oz = [max_sum(Xz_hat.cpu().numpy())]
    itv = get_ad_interval(Xz, Xz_hat, Oz[0], a, b, model)
    return itv[1] - min(zk, itv[1]), Oz


def run_parametric_wdgrl(X, etaj, n, threshold, model, ns):
    zk = -threshold

    list_zk = [zk]
    list_Oz = []

    while zk < threshold:
        Xz, a, b = compute_yz(X, etaj, zk, n)
        skz, Oz = parametric_wdgrl(Xz, a, b, n, zk, model)
        zk = zk + skz + 1e-3 
        # zk = min(zk, threshold)
        if zk < threshold:
            list_zk.append(zk)
        else:
            list_zk.append(threshold)
        list_Oz.append(Oz)
        # print(f'intervals: {zk-skz-1e-3} - {zk -1e-3}')
        # print(f'Anomaly index: {Oz}')
        # print('-------------')
    return list_zk, list_Oz
        
def cdf(mu, sigma, list_zk, list_Oz, etajTX, O):
    numerator = 0
    denominator = 0
    for each_interval in range(len(list_zk) - 1):
        al = list_zk[each_interval]
        ar = list_zk[each_interval + 1] - 1e-3

        if (np.array_equal(O, list_Oz[each_interval]) == False):
            continue

        denominator = denominator + mp.ncdf((ar - mu)/sigma) - mp.ncdf((al - mu)/sigma)
        if etajTX >= ar:
            numerator = numerator + mp.ncdf((ar - mu)/sigma) - mp.ncdf((al - mu)/sigma)
        elif (etajTX >= al) and (etajTX< ar):
            numerator = numerator + mp.ncdf((etajTX - mu)/sigma) - mp.ncdf((al - mu)/sigma)
    # print(f'numerator: {numerator}')
    # print(f'denominator: {denominator}')
    if denominator != 0:
        return float(numerator/denominator)
    else:
        return None
    
def max_sum(X):
    return np.argmax(np.sum(X, axis=1))

def get_interval(Xtj, a, b, model):
    layers = []

    for name, param in model.generator.named_children():
        temp = dict(param._modules)
        
        for layer_name in temp.values():
            if ('Linear' in str(layer_name)):
                layers.append('Linear')
            elif ('ReLU' in str(layer_name)):
                layers.append('ReLU')

    ptr = 0
    itv = [np.NINF, np.Inf]
    u = a
    v = b
    temp = Xtj
    weight = None
    bias = None
    for name, param in model.generator.named_parameters():
        if (layers[ptr] == 'Linear'):
            if ('weight' in name):
                weight = param.data.cpu().detach().numpy()
            elif ('bias' in name):
                bias = param.data.cpu().detach().numpy().reshape(-1, 1)
                ptr += 1
                temp = weight.dot(temp) + bias
                u = weight.dot(u) + bias
                v = weight.dot(v)

        if (ptr < len(layers) and layers[ptr] == 'ReLU'):
            ptr += 1
            sub_itv = [np.NINF, np.inf]
            for i in range(temp.shape[0]):
                if temp[i] > 0:
                    sub_itv = intersect(sub_itv, solve_linear_inequality(-u[i][0], -v[i][0]))
                else:
                    sub_itv = intersect(sub_itv, solve_linear_inequality(u[i][0], v[i][0]))
            itv = intersect(itv, sub_itv)

    return itv, u, v

def truncated_cdf(etajTy, mu, sigma, left, right):
    numerator = mp.ncdf((etajTy - mu) / sigma) - mp.ncdf((left - mu) / sigma)
    denominator = mp.ncdf((right - mu) / sigma) - mp.ncdf((left - mu) / sigma)
    # print(f'numerator: {numerator}')
    # print(f'denominator: {denominator}')
    if denominator != 0:
        return float(numerator/denominator)
    else:
        return None